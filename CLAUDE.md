# CLAUDE.md â€” AiNotes

## Project Overview

**AiNotes** is a personal AI knowledge base app with **voice as the primary input**. Users can also type, scan photos, and import documents. An on-device LLM + RAG engine powers everything: rewriting messy transcripts into clean notes, auto-classifying and filing them, finding related content, and answering questions about your own knowledge. **Fully on-device for privacy** â€” no data ever leaves the device.

**Phase 1 Status**: âœ… **COMPLETE** â€” Full foundation with unified smart input system

**Target**: Become the Notion/Mem.ai of voice-first knowledge apps. "My notes are perfectly organized without me doing anything."

---

## Product Vision

### What Users See
- "I just talk, and my thoughts are automatically organized"
- "I asked my notes something and got a detailed answer with sources"
- "My shopping list updated itself when I said 'also get bananas'"
- Everything is offline, no cloud, no account, complete privacy

### What Powers It
- **On-device STT** (sherpa_onnx): Moonshine model â†’ ~50ms latency
- **On-device LLM** (llamadart): Qwen 2.5 1.5B â†’ rewriting + classification + Q&A
- **On-device Embeddings** (flutter_gemma): EmbeddingGemma 300M â†’ semantic search
- **Vector Store** (ObjectBox): HNSW algorithm â†’ fast similarity search
- **RAG Engine**: Query â†’ retrieve similar notes â†’ LLM generates grounded answers
- **Storage**: Markdown files with YAML frontmatter â†’ human-readable, portable, LLM-friendly

---

## Phase 1: Foundation + Unified Input âœ… COMPLETE

### What Was Built

**UI Foundation**
- âœ… Theme system with dark mode (orange accent, category colors)
- âœ… 4-tab navigation: Home (grid) | Folders (list) | Ask (chat) | Settings
- âœ… Home screen: masonry grid with smart grouping (Today, This Week, Earlier)
- âœ… Folders screen: hierarchical list view grouped by category with timestamps
- âœ… Ask screen: chat interface with enhanced message bubbles
- âœ… Note detail screen: view/edit notes

**Unified Input System** (NEW architectural layer)
- âœ… **UniversalInputBar**: Single input on Home, Folders, Ask tabs (not Settings)
  - Placeholder: "What's on your mind?" (intent-agnostic)
  - Red gradient mic button (48x48px) â€” separate from main input
  - Camera icon for photo capture
- âœ… **IntentClassifier** (pluggable abstraction)
  - MockIntentClassifier: Regex-based implementation for Phase 1
  - Questions: what/when/where/who/how/why/find/show me â†’ Ask tab
  - Todos: remind me/need to/don't forget â†’ Todos category
  - Shopping: buy/get/purchase â†’ Shopping category
  - Ideas: idea/concept/brainstorm â†’ Ideas category
  - Default: general notes
- âœ… **UnifiedInputProvider** (StateNotifier)
  - Routes all input (text/voice/photo) through intent detection
  - Smart routing: questions navigate to Ask tab, notes stay in place
  - Integrates with ChatProvider and NotesProvider

**Data & Storage**
- âœ… Note model with freezed: id, originalText, rewrittenText, category, confidence, createdAt, tags, source
- âœ… NoteFileStore: Read/write markdown with YAML frontmatter
- âœ… ObjectBox integration: Note metadata index + FTS
- âœ… NoteRepository: Orchestrates file store + index
- âœ… NoteCategory enum: shopping, todos, ideas, general
- âœ… NoteSource enum: voice, text, photo, document, webClip

**Input Integration**
- âœ… Text capture: Routes through UnifiedInputProvider for intent detection
- âœ… Voice recording: Transcripts route through UnifiedInputProvider
- âœ… Chat interface: Integrated with Ask tab

**Polish & Fixes**
- âœ… Enhanced chat bubbles: Larger (340px), better spacing (16px), improved typography
- âœ… Android 16 Edge-to-Edge fix: SafeArea + BottomNavigationBar (fixes Pixel 8 UI overlap)
- âœ… Filter chips on Home: All | Shopping | Todos | Ideas | General
- âœ… Note card styling: Color-coded by category, source badges, confidence indicators

---

## Tech Stack (Phase 1 Implementation)

### Phase 1: Foundation (âœ… COMPLETE)
```yaml
# State Management
flutter_riverpod: ^3.0.0         # Reactive provider pattern, built-in DI
riverpod_annotation: ^3.0.0      # Code generation support

# Navigation
go_router: ^latest               # Declarative routing, deep linking

# Data Models
freezed: ^latest                 # Immutable models, pattern matching
json_serializable: ^latest       # JSON (de)serialization

# Storage
objectbox: ^latest               # Vector search + metadata index (HNSW)
path_provider: ^latest           # App-local file storage
yaml: ^latest                    # Parse YAML frontmatter

# UI
flutter_staggered_grid_view: ^latest # Masonry grid for home screen
flutter_animate: ^latest         # Smooth animations

# Utilities
uuid: ^latest                    # Unique IDs
shared_preferences: ^latest      # Simple preferences
```

### Phase 2: STT (Recording + Transcription)
```yaml
sherpa_onnx: ^1.12.24            # On-device STT (Moonshine model)
record: ^6.2.0                   # Audio recording with streaming
audio_waveforms: ^latest         # Real-time waveform visualization
pulsator: ^latest                # Pulse animation for mic button
permission_handler: ^latest      # Microphone permissions
```

### Phase 3: LLM Pipeline
```yaml
llamadart: ^0.4.0                # On-device LLM inference (GGUF models)
                                 # Default: Qwen 2.5 1.5B Q4_K_M
```

### Phase 4: RAG + Semantic Search
```yaml
flutter_gemma: ^latest           # On-device embeddings (EmbeddingGemma)
                                 # 768D embeddings, <200MB RAM
```

### Phase 5: Multi-Input Capture
```yaml
google_mlkit_text_recognition: ^latest # OCR for photos/receipts
pdfrx: ^latest                   # PDF text extraction
image_picker: ^latest            # Camera/gallery access
```

---

## Architecture

### Folder Structure (Feature-First)
```
lib/
â”œâ”€â”€ main.dart                     # App entry point
â”œâ”€â”€ app.dart                      # MaterialApp.router, theme, ProviderScope
â”‚
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ theme/
â”‚   â”‚   â”œâ”€â”€ app_theme.dart        # ThemeData configuration
â”‚   â”‚   â”œâ”€â”€ app_colors.dart       # ColorScheme extension (dark theme, orange accent)
â”‚   â”‚   â”œâ”€â”€ app_typography.dart   # Text styles (heading1-3, body, caption, etc)
â”‚   â”‚   â””â”€â”€ design_tokens.dart    # Spacing, radius, elevation constants
â”‚   â”‚
â”‚   â”œâ”€â”€ routing/
â”‚   â”‚   â””â”€â”€ app_router.dart       # GoRouter configuration (4 tabs + routes)
â”‚   â”‚
â”‚   â”œâ”€â”€ error/
â”‚   â”‚   â””â”€â”€ result.dart           # Result<T> sealed class (Failure/Success)
â”‚   â”‚
â”‚   â”œâ”€â”€ ai/ (Phase 2+ features marked)
â”‚   â”‚   â”œâ”€â”€ intent_classifier.dart        # âœ… Phase 1: Abstract interface
â”‚   â”‚   â”œâ”€â”€ mock_intent_classifier.dart   # âœ… Phase 1: Regex-based implementation
â”‚   â”‚   â”œâ”€â”€ llm_engine.dart               # Phase 3: Abstract LLM interface
â”‚   â”‚   â”œâ”€â”€ llamadart_engine.dart         # Phase 3: LLM implementation
â”‚   â”‚   â”œâ”€â”€ stt_engine.dart               # Phase 2: Abstract STT interface
â”‚   â”‚   â”œâ”€â”€ sherpa_stt_engine.dart        # Phase 2: STT implementation
â”‚   â”‚   â”œâ”€â”€ embedding_engine.dart         # Phase 4: Abstract embedding interface
â”‚   â”‚   â””â”€â”€ gemma_embedding_engine.dart   # Phase 4: Embedding implementation
â”‚   â”‚
â”‚   â”œâ”€â”€ rag/ (Phase 4+ features)
â”‚   â”‚   â”œâ”€â”€ rag_engine.dart       # Query â†’ retrieve â†’ augment â†’ generate
â”‚   â”‚   â”œâ”€â”€ chunker.dart          # Split into 400-512 token chunks
â”‚   â”‚   â”œâ”€â”€ context_builder.dart  # Build LLM context from retrieved chunks
â”‚   â”‚   â””â”€â”€ prompt_templates.dart # Rewrite, classify, Q&A, merge prompts
â”‚   â”‚
â”‚   â”œâ”€â”€ storage/
â”‚   â”‚   â”œâ”€â”€ note_file_store.dart  # âœ… Phase 1: Read/write markdown + YAML
â”‚   â”‚   â”œâ”€â”€ vector_store.dart     # Phase 4: ObjectBox vector embeddings
â”‚   â”‚   â””â”€â”€ note_index.dart       # âœ… Phase 1: ObjectBox metadata + FTS
â”‚   â”‚
â”‚   â””â”€â”€ constants.dart            # App-wide constants
â”‚
â”œâ”€â”€ features/
â”‚   â”œâ”€â”€ unified_input/            # âœ… Phase 1: NEW architectural layer
â”‚   â”‚   â”œâ”€â”€ domain/
â”‚   â”‚   â”‚   â””â”€â”€ input_intent.dart # sealed class: NoteIntent | QuestionIntent
â”‚   â”‚   â””â”€â”€ providers/
â”‚   â”‚       â””â”€â”€ unified_input_provider.dart # StateNotifier: classify + route
â”‚   â”‚
â”‚   â”œâ”€â”€ folders/                  # âœ… Phase 1: NEW browse mode
â”‚   â”‚   â””â”€â”€ presentation/
â”‚   â”‚       â””â”€â”€ folders_screen.dart # Hierarchical list grouped by category
â”‚   â”‚
â”‚   â”œâ”€â”€ notes/
â”‚   â”‚   â”œâ”€â”€ domain/
â”‚   â”‚   â”‚   â”œâ”€â”€ note.dart              # âœ… Phase 1: Note model (freezed)
â”‚   â”‚   â”‚   â”œâ”€â”€ note_category.dart     # âœ… Phase 1: Category enum + colors
â”‚   â”‚   â”‚   â””â”€â”€ note_source.dart       # âœ… Phase 1: Source enum (voice/text/photo/doc)
â”‚   â”‚   â”œâ”€â”€ presentation/
â”‚   â”‚   â”‚   â”œâ”€â”€ note_detail_screen.dart # âœ… Phase 1: View/edit
â”‚   â”‚   â”‚   â””â”€â”€ note_card.dart         # âœ… Phase 1: Note card widget
â”‚   â”‚   â””â”€â”€ providers/
â”‚   â”‚       â”œâ”€â”€ notes_provider.dart     # âœ… Phase 1: Main notes provider
â”‚   â”‚       â””â”€â”€ notes_repository.dart   # âœ… Phase 1: File store + index
â”‚   â”‚
â”‚   â”œâ”€â”€ home/
â”‚   â”‚   â””â”€â”€ presentation/
â”‚   â”‚       â”œâ”€â”€ home_screen.dart    # âœ… Phase 1: Masonry grid view
â”‚   â”‚       â”œâ”€â”€ note_card.dart      # âœ… Phase 1: Card with category color
â”‚   â”‚       â””â”€â”€ filter_chips.dart   # âœ… Phase 1: Category filter row
â”‚   â”‚
â”‚   â”œâ”€â”€ ask/
â”‚   â”‚   â”œâ”€â”€ domain/
â”‚   â”‚   â”‚   â””â”€â”€ chat_message.dart   # âœ… Phase 1: UserMessage | AiMessage
â”‚   â”‚   â”œâ”€â”€ presentation/
â”‚   â”‚   â”‚   â”œâ”€â”€ ask_screen.dart     # âœ… Phase 1: Chat interface
â”‚   â”‚   â”‚   â””â”€â”€ message_bubble.dart # âœ… Phase 1: Enhanced message bubbles
â”‚   â”‚   â””â”€â”€ providers/
â”‚   â”‚       â””â”€â”€ chat_provider.dart  # âœ… Phase 1: Chat message state
â”‚   â”‚
â”‚   â”œâ”€â”€ recording/                 # Phase 2: STT integration
â”‚   â”‚   â”œâ”€â”€ domain/
â”‚   â”‚   â”‚   â””â”€â”€ recording_state.dart
â”‚   â”‚   â”œâ”€â”€ presentation/
â”‚   â”‚   â”‚   â”œâ”€â”€ recording_screen.dart
â”‚   â”‚   â”‚   â”œâ”€â”€ waveform_widget.dart
â”‚   â”‚   â”‚   â””â”€â”€ record_button.dart
â”‚   â”‚   â””â”€â”€ providers/
â”‚   â”‚       â””â”€â”€ recording_provider.dart
â”‚   â”‚
â”‚   â”œâ”€â”€ capture/                   # Phase 5: Multi-input
â”‚   â”‚   â”œâ”€â”€ domain/
â”‚   â”‚   â”œâ”€â”€ presentation/
â”‚   â”‚   â”‚   â”œâ”€â”€ text_capture_screen.dart
â”‚   â”‚   â”‚   â””â”€â”€ photo_capture_screen.dart
â”‚   â”‚   â””â”€â”€ providers/
â”‚   â”‚
â”‚   â”œâ”€â”€ processing/                # Phase 3: LLM pipeline
â”‚   â”‚   â”œâ”€â”€ domain/
â”‚   â”‚   â”‚   â”œâ”€â”€ processing_pipeline.dart
â”‚   â”‚   â”‚   â””â”€â”€ classification.dart
â”‚   â”‚   â””â”€â”€ providers/
â”‚   â”‚       â””â”€â”€ pipeline_provider.dart
â”‚   â”‚
â”‚   â”œâ”€â”€ search/                    # Phase 4: Hybrid search
â”‚   â”‚   â”œâ”€â”€ presentation/
â”‚   â”‚   â”‚   â””â”€â”€ search_screen.dart
â”‚   â”‚   â””â”€â”€ providers/
â”‚   â”‚       â””â”€â”€ search_provider.dart
â”‚   â”‚
â”‚   â”œâ”€â”€ models_manager/            # Phase 3+: Download/manage ML models
â”‚   â”‚   â”œâ”€â”€ domain/
â”‚   â”‚   â”‚   â”œâ”€â”€ ml_model.dart
â”‚   â”‚   â”‚   â””â”€â”€ download_state.dart
â”‚   â”‚   â”œâ”€â”€ presentation/
â”‚   â”‚   â”‚   â””â”€â”€ model_manager_screen.dart
â”‚   â”‚   â””â”€â”€ providers/
â”‚   â”‚       â””â”€â”€ model_manager_provider.dart
â”‚   â”‚
â”‚   â”œâ”€â”€ settings/                  # Phase 5: App settings
â”‚   â”‚   â””â”€â”€ presentation/
â”‚   â”‚       â””â”€â”€ settings_screen.dart
â”‚   â”‚
â”‚   â””â”€â”€ onboarding/                # Phase 5: First-run experience
â”‚       â””â”€â”€ presentation/
â”‚           â”œâ”€â”€ onboarding_screen.dart
â”‚           â”œâ”€â”€ privacy_page.dart
â”‚           â”œâ”€â”€ permission_page.dart
â”‚           â””â”€â”€ model_download_page.dart
â”‚
â””â”€â”€ shared/
    â””â”€â”€ widgets/
        â”œâ”€â”€ app_shell.dart              # âœ… Phase 1: Bottom nav + tab scaffold
        â”œâ”€â”€ universal_input_bar.dart    # âœ… Phase 1: Unified input on 3 tabs
        â”œâ”€â”€ gradient_button.dart        # âœ… Phase 1: Orange gradient button
        â””â”€â”€ app_bottom_sheet.dart       # Phase 2+: Reusable bottom sheet
```

### Key Architectural Decisions (Phase 1)

**1. Navigation: 4 Tabs (not 5)**
- Home (grid) | Folders (list) | Ask (chat) | Settings
- Removed Search tab â†’ functionality in Folders + semantic search (Phase 4)
- Removed Organize tab â†’ deferred to Phase 3+ with LLM confidence
- Rationale: Cleaner, less overwhelming, Settings more useful

**2. Unified Input Bar (not tab-specific inputs)**
- Single UniversalInputBar on Home, Folders, Ask (not Settings)
- Reduces cognitive load, enables smart routing
- Placeholder "What's on your mind?" is intent-agnostic

**3. Microphone as Separate Red Button (not center FAB)**
- 48x48px gradient button always visible on all input tabs
- More accessible one-handed, consistent with modern apps (ChatGPT, Perplexity)
- Cleaner nav without FAB cutout

**4. Intent Classification Layer (new, Phase 1)**
- MockIntentClassifier: Regex patterns for immediate smart routing
- Easy to swap with LLM-based classifier in Phase 3
- Questions â†’ Ask tab, Notes â†’ stay in place (magic!)
- Bridges UI and AI layers before LLM is ready

**5. Simplified Recording Flow**
- Full-screen RecordingScreen (proven UX from Otter.ai)
- Processing animations deferred to Phase 3 (when LLM ready)
- Transcript still routes through UnifiedInputProvider

**6. Folders View (new, Phase 1)**
- Alternative browse mode to grid (some users prefer lists)
- Shows category icons, note counts, timestamps
- Less CPU/RAM than masonry for large collections
- Enables future: collapsible categories, tags

### Data Model

```dart
@freezed
class Note with _$Note {
  const factory Note({
    required String id,
    required String originalText,           // Raw input (transcript/OCR/text)
    required String rewrittenText,          // Cleaned by LLM (Phase 3+)
    required NoteCategory category,
    String? customCategory,
    required double confidence,             // 0.0-1.0, filled by LLM (Phase 3+)
    required DateTime createdAt,
    DateTime? updatedAt,
    @Default([]) List<String> tags,        // Extracted by LLM (Phase 3+)
    @Default(NoteSource.text) NoteSource source,
    Duration? audioDuration,                // For voice notes
    String? filePath,                       // Path to .md file
  }) = _Note;
}

enum NoteCategory { shopping, todos, ideas, general }
enum NoteSource { voice, text, photo, document, webClip }
```

### Storage: Markdown + YAML Frontmatter

Notes are stored as human-readable `.md` files with YAML frontmatter:

```markdown
---
id: abc123def456
category: shopping
confidence: 0.92
source: voice
created: 2026-02-11T10:30:00Z
updated: 2026-02-11T10:30:00Z
tags: [groceries, weekly]
audio_duration: 45s
---

# Groceries

- Milk
- Bread
- Eggs
- Coffee
- Oat milk

---
<!-- original -->
okay so um I need to get milk and bread and eggs oh and also coffee and oat milk
```

**Why markdown?**
- LLM-friendly: Most token-efficient format, 60.7% accuracy vs CSV
- Human-readable: Edit in any text editor, version control friendly
- Portable: Notes survive the app, sync via cloud (iCloud, Google Drive, etc)
- Future-proof: Open format, not locked to any platform

### Unified Input Flow (Phase 1)

```
User Input (Text, Voice, or Photo)
    â†“
UniversalInputBar (Home, Folders, Ask tabs)
    â”œâ”€ Text: Tap input field
    â”œâ”€ Voice: Tap red mic button â†’ RecordingScreen â†’ transcript
    â””â”€ Photo: Tap camera icon â†’ future OCR (Phase 5)
    â†“
Text Normalized (from STT/OCR/typing)
    â†“
UnifiedInputProvider
    â”œâ”€ IntentClassifier.classify(text)
    â”‚
    â”œâ”€ Question detected? (regex: what/when/where/who/how/why)
    â”‚  â””â”€ ChatProvider.sendMessage(text)
    â”‚  â””â”€ Navigate to Ask tab
    â”‚
    â””â”€ Note detected? (statement/reminder/observation)
       â”œâ”€ SuggestCategory (regex: shopping/todos/ideas/general)
       â””â”€ NotesProvider.createNote()
       â””â”€ Stay on current tab
    â†“
Note saved as .md file + ObjectBox index
```

---

## Current Feature Status

### âœ… Phase 1: Complete
- [x] Full theme system with dark mode + orange accent
- [x] 4-tab navigation with bottom nav bar
- [x] Home screen: masonry grid with smart grouping
- [x] Folders screen: hierarchical list view
- [x] Ask screen: chat interface
- [x] UniversalInputBar on 3 tabs
- [x] Intent classification (regex-based mock)
- [x] Text/voice input routing through UnifiedInputProvider
- [x] Note storage (markdown + YAML)
- [x] ObjectBox indexing
- [x] Enhanced chat bubbles
- [x] Android 16 Edge-to-Edge fix

### ðŸ”® Phase 2: Recording + STT (Next)
- [ ] sherpa_onnx integration
- [ ] Live transcription during recording
- [ ] Waveform visualization
- [ ] Timestamp markers for transcribed text

### ðŸ”® Phase 3: LLM Pipeline + Auto-Organization
- [ ] llamadart integration
- [ ] LLM rewriting (clean messy transcripts)
- [ ] LLM classification (category + confidence)
- [ ] Processing animation (âœ“ Transcribed â†’ â—Ž Rewriting â†’ â—‹ Classifying)
- [ ] Replace MockIntentClassifier with LLM-based

### ðŸ”® Phase 4: Embeddings + RAG Core
- [ ] flutter_gemma integration (EmbeddingGemma)
- [ ] Vector embeddings for all notes
- [ ] Semantic search (find related notes)
- [ ] "Ask your notes" RAG-powered Q&A
- [ ] Smart note merging ("Also get bananas" â†’ updates grocery list)

### ðŸ”® Phase 5: Multi-Input + Polish
- [ ] Text capture (type/paste)
- [ ] Photo capture with OCR (google_mlkit_text_recognition)
- [ ] PDF import (pdfrx)
- [ ] Onboarding flow (5 screens)
- [ ] Settings screen (model selection, confidence thresholds)

### ðŸ”® Phase 6: Intelligence Layer
- [ ] Auto-linking (new notes show related ones)
- [ ] Smart tagging (LLM extracts tags)
- [ ] Note clustering (group similar ideas)
- [ ] Weekly digest (LLM summarizes ideas, todos, patterns)
- [ ] Custom categories

---

## Key Patterns & Principles

### Riverpod Providers
- **StateNotifier** for mutable state (UnifiedInputProvider, ChatProvider)
- **FutureProvider** for async data (notesProvider, searchProvider)
- **Provider** for computed/derived state (filteredNotesProvider)
- **NotifierProvider** for complex state management
- Riverpod overrides for testing (mock STTEngine, LLMEngine, etc)

### Error Handling
- **Result<T> sealed class**: Failure (message) | Success (data)
- No exceptions for expected errors
- Dart 3.0+ exhaustive switch for pattern matching

### Intent Detection Architecture
```dart
// Abstract interface (pluggable)
abstract class IntentClassifier {
  Future<InputIntent> classify(String text);
}

// Phase 1: Regex-based mock
class MockIntentClassifier implements IntentClassifier {
  // Pattern matching for questions, todos, shopping, ideas
}

// Phase 3: LLM-based (to be implemented)
class LLMIntentClassifier implements IntentClassifier {
  // Few-shot prompt to llamadart for high-accuracy classification
}
```

### Storage Abstraction
```dart
// Markdown file store (notes are portable .md files)
class NoteFileStore {
  Future<void> saveNote(Note note);  // Write .md file with YAML frontmatter
  Future<Note?> loadNote(String id); // Parse .md + YAML
  Future<List<Note>> loadAllNotes(); // Read all notes directory
}

// ObjectBox indexing (fast queries)
class NoteIndex {
  // Metadata index (id, category, createdAt, tags)
  // Full-text search (rewrittenText search)
  // Phase 4: Vector embeddings (semantic search)
}
```

---

## How to Run

### Prerequisites
- Flutter 3.0+ (stable channel)
- Dart 3.0+
- Android Studio (for emulator) or physical device

### Build & Run
```bash
# Get dependencies
flutter pub get

# Code generation (freezed + objectbox)
dart run build_runner build --delete-conflicting-outputs

# Run on device
flutter run

# Run in release mode (optimized)
flutter run --release

# Build APK
flutter build apk --split-per-abi
```

### Run Tests
```bash
flutter test

# With coverage
flutter test --coverage
lcov --list coverage/lcov.info
```

### Analyze Code
```bash
# Lint check
flutter analyze

# Format code
dart format .

# Run formatter + analyzer + tests
flutter run pre-commit hook
```

---

## Key Files to Know

### Theme & Design
- `lib/core/theme/app_colors.dart` â€” Color palette (dark mode, orange, categories)
- `lib/core/theme/app_typography.dart` â€” Text styles
- `lib/core/theme/design_tokens.dart` â€” Spacing, radius, elevation

### Navigation
- `lib/core/routing/app_router.dart` â€” Route definitions (Home, Folders, Ask, Settings)
- `lib/shared/widgets/app_shell.dart` â€” Bottom nav bar + tab scaffold

### Core Features
- `lib/features/unified_input/providers/unified_input_provider.dart` â€” Smart input routing
- `lib/core/ai/mock_intent_classifier.dart` â€” Question vs note detection
- `lib/shared/widgets/universal_input_bar.dart` â€” Input bar widget

### Data & Storage
- `lib/features/notes/domain/note.dart` â€” Note data model
- `lib/core/storage/note_file_store.dart` â€” Markdown file read/write
- `lib/core/storage/note_index.dart` â€” ObjectBox indexing

### UI Screens
- `lib/features/home/presentation/home_screen.dart` â€” Masonry grid
- `lib/features/folders/presentation/folders_screen.dart` â€” List view
- `lib/features/ask/presentation/ask_screen.dart` â€” Chat interface

---

## Immediate Next Steps (Phase 2)

1. **Add sherpa_onnx package** for on-device STT
2. **Create STTEngine abstraction** (like LLMEngine, EmbeddingEngine)
3. **Implement SherpaSTTEngine** with Moonshine model
4. **Wire recording â†’ STT â†’ live transcription** in RecordingScreen
5. **Test end-to-end**: Record audio â†’ see live transcript on device
6. **Integrate with UnifiedInputProvider**: Transcript â†’ intent detection â†’ routing

---

## References

- **Product Spec**: `docs/how_it_works.md`
- **Implementation Plan**: `docs/implementation_plan.md` (detailed architecture + phases)
- **Tech Stack Details**: See `Part 1: Tech Stack` in implementation_plan.md
- **UI/UX Architecture**: See `Part 3: UI/UX Architecture` in implementation_plan.md

---

## Design Philosophy

1. **Voice-first, but text-friendly** â€” Voice is primary, but typing should feel native
2. **Organize = Understand** â€” The app understands your thoughts by organizing them
3. **Zero friction** â€” Smart routing (no "is this a note or a question?" prompt)
4. **All on-device** â€” Privacy by default, no cloud accounts, no tracking
5. **Beautiful dark mode** â€” Reduces eye strain, orange accent for warmth
6. **Pluggable AI** â€” Easy to swap STT/LLM/embedding implementations for better models

---

Last Updated: February 2026
Phase 1 Completion: âœ… Complete
Next Phase: Phase 2 - Recording + STT Integration
